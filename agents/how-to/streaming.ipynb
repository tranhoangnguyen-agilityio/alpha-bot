{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LangSmith tracking\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "@tool\n",
    "async def where_cat_is_hiding() ->  str:\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    return random.choice([\"under the bed\", \"on the shelf\"])\n",
    "\n",
    "@tool\n",
    "async def get_items(place: str) -> str:\n",
    "    \"\"\"Use this tool to lookup which items are in the given  place. \"\"\"\n",
    "    if \"bed\" in place:  # For under the bed\n",
    "        return \"socks, shoes and dust bunnies\"\n",
    "    if \"shelf\" in place:  # For 'shelf'\n",
    "        return \"books, penciles and pictures\"\n",
    "    else:  # if the agent decides to ask about a different place\n",
    "        return \"cat snacks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION** Please note that we associated the name Agent with our agent using \"run_name\"=\"Agent\". We'll use that fact later on with the astream_events API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use  -  you  can modify  this\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "# print(prompt.messages)\n",
    "\n",
    "tools = [get_items, where_cat_is_hiding]\n",
    "\n",
    "agent  = create_openai_tools_agent(model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Intermediate Steps\n",
    "\n",
    "We’ll use .stream method of the AgentExecutor to stream the agent’s intermediate steps.\n",
    "\n",
    "The output from .stream alternates between (action, observation) pairs, finally concluding with the answer if the agent achieved its objective.\n",
    "\n",
    "It’ll look like this:\n",
    "\n",
    "- actions output\n",
    "- observations output\n",
    "- actions output\n",
    "- observations output\n",
    "\n",
    "… (continue until goal is reached) …\n",
    "\n",
    "Then, if the final goal is reached, the agent will output the final answer.\n",
    "\n",
    "The contents of these outputs are summarized here:\n",
    "\n",
    "| Output       |      Contents      |\n",
    "|----------    |:-------------:|\n",
    "| Actions      |  `actions` `AgentAction` or a subclass, `messages` chat messages corresponding to action invocation |\n",
    "| Observations |  `steps` History of what the agent did so far, including the current action and its observation, `messages` chat message with function invocation results (aka observations)   |\n",
    "| Final answer | `output` `AgentFinish`, `messages` chat messages with the final output |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "{'actions': [...], 'messages': [...]}\n",
      "---------\n",
      "{'messages': [...], 'steps': [...]}\n",
      "---------\n",
      "{'actions': [...], 'messages': [...]}\n",
      "---------\n",
      "{'messages': [...], 'steps': [...]}\n",
      "---------\n",
      "{'messages': [...],\n",
      " 'output': 'The items located where the cat is hiding (on the shelf) are '\n",
      "           'books, pencils, and pictures.'}\n"
     ]
    }
   ],
   "source": [
    "# Note: We use `pprint` to print only to depth 1, it makes it easier to see the output from a high level, before digging in.\n",
    "\n",
    "import pprint\n",
    "\n",
    "chunks = []\n",
    "\n",
    "async for chunk in agent_executor.astream({\n",
    "    \"input\": \"What is the items are located  where the cat is hiding?\"\n",
    "}):\n",
    "    chunks.append(chunk)\n",
    "    print(\"---------\")\n",
    "    pprint.pprint(chunk, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using  Messages\n",
    "\n",
    "You can access the underlying `messages`` from the outputs. Using messages can be nice when working with chat applications - because everything is a message!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_iMU3W45ykVrU6sxBB9aVMzSM', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_iMU3W45ykVrU6sxBB9aVMzSM')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0][\"actions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_iMU3W45ykVrU6sxBB9aVMzSM', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})]\n",
      "[FunctionMessage(content='under the bed', name='where_cat_is_hiding')]\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4SGUd9YSFmPZmn86ePu53lcw', 'function': {'arguments': '{\"place\":\"under the bed\"}', 'name': 'get_items'}, 'type': 'function'}]})]\n",
      "[FunctionMessage(content='socks, shoes and dust bunnies', name='get_items')]\n",
      "[AIMessage(content='The items located where the cat is hiding (under the bed) are socks, shoes, and dust bunnies.')]\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(chunk[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AgentAction/Observation\n",
    "\n",
    "The outputs also contain richer structured information inside of actions and steps, which could be useful in some situations, but can also be harder to parse.\n",
    "\n",
    "`Attention` AgentFinish is not available as part of the `streaming` method. If this is something you’d like to be added, please start a discussion on github and explain why its needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling  Tool:  `where_cat_is_hiding` with input `{}`\n",
      "-----\n",
      "Tool Result: `under the bed`\n",
      "-----\n",
      "Calling  Tool:  `get_items` with input `{'place': 'under the bed'}`\n",
      "-----\n",
      "Tool Result: `socks, shoes and dust bunnies`\n",
      "-----\n",
      "Final Output: The items located where the cat is hiding (under the bed) are socks, shoes, and dust bunnies.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "async for chunk  in agent_executor.astream({\n",
    "    \"input\": \"What is the items are located where the cat is hiding\"\n",
    "}):\n",
    "    # Agent Action\n",
    "    if \"actions\" in chunk:\n",
    "        for action in chunk[\"actions\"]:\n",
    "            print(f\"Calling  Tool:  `{action.tool}` with input `{action.tool_input}`\")\n",
    "    \n",
    "    # Observation\n",
    "    if \"steps\" in chunk:\n",
    "        for step in chunk[\"steps\"]:\n",
    "            print(f\"Tool Result: `{step.observation}`\")\n",
    "    \n",
    "    # Final result\n",
    "    if \"output\" in chunk:\n",
    "        # print(f'Final Output: {chunk[\"output\"]}')\n",
    "        print(f'Final Output: {chunk[\"output\"]}')\n",
    "    # else:\n",
    "    #     raise ValueError()\n",
    "    \n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Streaming With Events\n",
    "\n",
    "Use the `astream_events`` API in case the default behavior of stream does not work for your application (e.g., if you need to stream individual tokens from the agent or surface steps occuring **within** tools).\n",
    "\n",
    "⚠️ This is a **beta** API, meaning that some details might change slightly in the future based on usage. ⚠️ To make sure all callbacks work properly, use `async` code throughout. Try avoiding mixing in sync versions of code (e.g., sync versions of tools).\n",
    "\n",
    "Let’s use this API to stream the following events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n",
      "--\n",
      "Starting tool: where_cat_is_hiding with inputs: {}\n",
      "Done tool: where_cat_is_hiding\n",
      "Tool output was: under the bed\n",
      "--\n",
      "--\n",
      "Starting tool: get_items with inputs: {'place': 'under the bed'}\n",
      "Done tool: get_items\n",
      "Tool output was: socks, shoes and dust bunnies\n",
      "--\n",
      "The| cat| is| hiding| under| the| bed|.| In| that| location|,| you| can| find| socks|,| shoes|,| and| dust| b|unn|ies|.|\n",
      "--\n",
      "Done agent: Agent with output: The cat is hiding under the bed. In that location, you can find socks, shoes, and dust bunnies.\n"
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Events from within Tools\n",
    "\n",
    "If your tool leverages LangChain runnable objects (e.g., LCEL chains, LLMs, retrievers etc.) and you want to stream events from those objects as well, you’ll need to make sure that callbacks are propagated correctly.\n",
    "\n",
    "To see how to pass callbacks, let’s re-implement the get_items tool to make it use an LLM and pass callbacks to that LLM. Feel free to adapt this to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def get_items_with_callbacks(place: str, callbacks: Callbacks) -> str:  # <--- Accept callbacks\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    print(\"DEBUG\")\n",
    "    print(callbacks)\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Can you tell me what kind of items i might find in the following place: '{place}'. \"\n",
    "                \"List at least 3 such items separating them by a comma. And include a brief description of each item..\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    chain = template | model.with_config(\n",
    "        {\n",
    "            \"run_name\": \"Get Items LLM\",\n",
    "            \"tags\": [\"tool_llm\"],\n",
    "            \"callbacks\": callbacks,  # <-- Propagate callbacks\n",
    "        }\n",
    "    )\n",
    "    chunks = [chunk async for chunk in chain.astream({\"place\": place})]\n",
    "    return \"\".join(chunk.content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n",
      "--\n",
      "Starting tool: where_cat_is_hiding with inputs: {}\n",
      "Done tool: where_cat_is_hiding\n",
      "Tool output was: on the shelf\n",
      "--\n",
      "--\n",
      "Starting tool: get_items_with_callbacks with inputs: {'place': 'on the shelf'}\n",
      "DEBUG\n",
      "<langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7f75e35ed890>\n",
      "1|.| Books| -| On| the| shelf|,| you| may| find| a| variety| of| books| ranging| from| fiction| to| non|-fiction|,| novels| to| reference| books|.| Books| are| typically| organized| by| genre| or| author| for| easy| browsing|.\n",
      "\n",
      "|2|.| Photo| frames| -| Photo| frames| are| commonly| found| on| shelves| to| display| cherished| memories| and| moments| captured| in| photographs|.| They| come| in| various| sizes|,| shapes|,| and| materials| to| suit| different| decor| styles|.\n",
      "\n",
      "|3|.| Decor|ative| figur|ines| -| Decor|ative| figur|ines| such| as| sculptures|,| statues|,| or| small| ornaments| are| often| placed| on| shelves| to| add| a| personal| touch| to| the| space|.| They| can| be| made| of| ceramic|,| glass|,| metal|,| or| wood|,| and| may| depict| animals|,| people|,| or| abstract| designs|.|Done tool: get_items_with_callbacks\n",
      "Tool output was: 1. Books - On the shelf, you may find a variety of books ranging from fiction to non-fiction, novels to reference books. Books are typically organized by genre or author for easy browsing.\n",
      "\n",
      "2. Photo frames - Photo frames are commonly found on shelves to display cherished memories and moments captured in photographs. They come in various sizes, shapes, and materials to suit different decor styles.\n",
      "\n",
      "3. Decorative figurines - Decorative figurines such as sculptures, statues, or small ornaments are often placed on shelves to add a personal touch to the space. They can be made of ceramic, glass, metal, or wood, and may depict animals, people, or abstract designs.\n",
      "--\n",
      "The| cat| is| hiding| on| the| shelf|.| In| that| location|,| you| can| find| the| following| items|:\n",
      "\n",
      "|1|.| Books| -| A| variety| of| books| ranging| from| fiction| to| non|-fiction|,| novels| to| reference| books|.\n",
      "|2|.| Photo| frames| -| Frames| to| display| cherished| memories| and| photographs|.\n",
      "|3|.| Decor|ative| figur|ines| -| Sculpt|ures|,| statues|,| or| small| ornaments| for| decoration|.|\n",
      "--\n",
      "Done agent: Agent with output: The cat is hiding on the shelf. In that location, you can find the following items:\n",
      "\n",
      "1. Books - A variety of books ranging from fiction to non-fiction, novels to reference books.\n",
      "2. Photo frames - Frames to display cherished memories and photographs.\n",
      "3. Decorative figurines - Sculptures, statues, or small ornaments for decoration.\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "tools = [get_items_with_callbacks, where_cat_is_hiding]\n",
    "\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")\n",
    "\n",
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other approaches\n",
    "\n",
    "**Using astream_log**\n",
    "\n",
    "**Note** You can also use the `astream_log` API. This API produces a granular log of all events that occur during execution. The log format is based on the `JSONPatch` standard. It’s granular, but requires effort to parse. For this reason, we created the astream_events API instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
