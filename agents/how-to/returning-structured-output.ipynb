{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning Structured Output\n",
    "\n",
    "This notebook covers how to have an agent return a structured output. By default, most of the agents return a single string. It can often be useful to have an agent return something with more structure.\n",
    "\n",
    "A good example of this is an agent tasked with doing question-answering over some sources. Let’s say we want the agent to respond not only with the answer, but also a list of the sources used. We then want our output to roughly follow the schema below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    \"\"\"Final response to the question being asked\"\"\"\n",
    "    answer: str = Field(description=\"The final answer to response to the user\")\n",
    "    sources: List[int] =  Field(description=\"List of page chunks that contain answer to the question. Only include a page chunk if it contains relevant information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will do some setup work to create our retriever over some mock data containing the “State of the Union” address. Importantly, we will add a “page_chunk” tag to the metadata of each document. This is just some fake data intended to simulate a source field. In practice, this would more likely be the URL or path of a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document\n",
    "loader = TextLoader(\"../state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split document into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Here is where we add in the fake source information\n",
    "for i, doc in enumerate(texts):\n",
    "    doc.metadata[\"page_chunk\"] = i\n",
    "\n",
    "# Create our retriever\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"state-of-union-retriever\",\n",
    "    \"Query a retriever to get information about state of the union address\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create response schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Final response to the question being asked\"\"\"\n",
    "    answer: str = Field(description=\"The final answer to respond to the user\")\n",
    "    sources: List[int] = Field(\n",
    "        description=\"List of page chunks that contain answer to the question. Only include a page chunk if it contains relevant information\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the custom parsing logic\n",
    "\n",
    "We now create some custom parsing logic. How this works is that we will pass the Response schema to the OpenAI LLM via their functions parameter. This is similar to how we pass tools for the agent to use.\n",
    "\n",
    "When the Response function is called by OpenAI, we want to use that as a signal to return to the user. When any other function is called by OpenAI, we treat that as a tool invocation.\n",
    "\n",
    "Therefore, our parsing logic has the following blocks:\n",
    "\n",
    "- If no function is called, assume that we should use the response to respond to the user, and therefore return AgentFinish\n",
    "- If the Response function is called, respond to the user with the inputs to that function (our structured output), and therefore return AgentFinish\n",
    "- If any other function is called, treat that as a tool invocation, and therefore return AgentActionMessageLog\n",
    "\n",
    "Note that we are using AgentActionMessageLog rather than AgentAction because it lets us attach a log of messages that we can use in the future to pass back into the agent prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.agents import AgentActionMessageLog, AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(output):\n",
    "    # If no function was invoked, return to user\n",
    "    if \"function_call\" not in output.additional_kwargs:\n",
    "        return AgentFinish(return_values={\"output\": output.content}, log=output.content)\n",
    "\n",
    "    # Parse out the function call\n",
    "    function_call = output.additional_kwargs[\"function_call\"]\n",
    "    name = function_call[\"name\"]\n",
    "    inputs = json.loads(function_call[\"arguments\"])\n",
    "\n",
    "    # If the Response function was invoked, return to the user with the function inputs\n",
    "    if name == \"Response\":\n",
    "        return AgentFinish(return_values=inputs, log=str(function_call))\n",
    "    # Otherwise, return an agent action\n",
    "    else:\n",
    "        return AgentActionMessageLog(\n",
    "            tool=name, tool_input=inputs, log=\"\", message_log=[output]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "We can now put this all together! The components of this agent are:\n",
    "\n",
    "- prompt: a simple prompt with placeholders for the user’s question and then the `agent_scratchpad` (any intermediate steps)\n",
    "- tools: we can attach the tools and `Response` format to the LLM as functions\n",
    "- format scratchpad: in order to format the agent_scratchpad from intermediate steps, we will use the standard `format_to_openai_function_messages`. This takes intermediate steps and formats them as AIMessages and FunctionMessages.\n",
    "- output parser: we will use our custom parser above to parse the response of the LLM\n",
    "- AgentExecutor: we will use the standard AgentExecutor to run the loop of agent-tool-agent-tool…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "llm_with_tools = llm.bind_functions([retriever_tool, Response])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        # Format agent scratchpad from intermediate steps\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | parse\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(tools=[retriever_tool], agent=agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"what did the president say about ketanji brown jackson\"},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
