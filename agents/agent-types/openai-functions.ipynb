{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet  langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialize Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_visualizer import visualize, visualize_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LangSmith tracking\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"What is Langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demo():\n",
    "    return agent_executor.invoke({\"input\": \"What is Langchain?\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-06 10:59.13.555323 [info     ] Trace: http://127.0.0.1:8935/traces/01HR8YMN4ED121WBF2PZ2N31D1\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "2024-03-06 10:59.13.712097 [info     ] Starting server, set OUGHT_ICE_AUTO_SERVER=0 to disable.\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m2024-03-06 10:59.14.655385 [info     ] Server started! Run `python -m ice.server stop` to stop it.\n",
      "2024-03-06 10:59.14.656850 [info     ] Opening trace in browser, set OUGHT_ICE_AUTO_BROWSER=0 to disable.\n",
      "\u001b[36;1m\u001b[1;3m[{'url': 'https://www.langchain.com/', 'content': 'Join Discord\\nContribute on GitHub\\n5.3M\\nMonthly Downloads\\n67k\\nGithub Stars\\n1800+\\nContributors\\n34k+\\nApps Powered\\nReady to build?\\nGo To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nContact Sales\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter Chatbots\\nQ&A Over Docs\\nSummarization\\nCopilots\\nWorkflow Automation\\nDocument Analysis\\nCustom Search\\nHarness the powerâ€“and wrangle the complexityâ€“ of LLMs\\nGet from proof-of-concept to production on one platform\\nRely on a set of tools built especially for non-deterministic models\\nLeverage new cognitive architectures and battle-tested orchestration\\nThanks to our contributors and partners for making LangChain awesome\\nWhen you build with LangChain, you build alongside a community of developers advancing the frontier of whatâ€™s possible with LLMs.\\n ðŸ¦œðŸ”— LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\nðŸ¦œðŸ”— LangChain\\nðŸ¦œðŸ”— LangChain\\nLangChain Expression Language makes it easy to create custom chains.\\n Go To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nA complete set of powerful building blocks\\nA complete set of powerful building blocks\\n Try it out here\\nGet your LLM application from prototype to production\\nGet your LLM application from prototype to production\\nBuild context-aware, reasoning applications with LangChainâ€™s flexible abstractions and AI-first toolkit.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mLangchain appears to be a platform that offers LangChain, LangSmith, and Retrieval, among other products and use-cases. It seems to be focused on providing tools for building context-aware, reasoning applications with flexible abstractions and an AI-first toolkit. You can find more information on their website: [Langchain](https://www.langchain.com/)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is Langchain?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Langchain appears to be a platform that offers LangChain, LangSmith, and Retrieval, among other products and use-cases. It seems to be focused on providing tools for building context-aware, reasoning applications with flexible abstractions and an AI-first toolkit. You can find more information on their website: [Langchain](https://www.langchain.com/)'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'input'\u001b[0m: \u001b[32m'What is Langchain?'\u001b[0m,\n",
       "    \u001b[32m'output'\u001b[0m: \u001b[32m'Langchain appears to be a platform that offers LangChain, LangSmith, and Retrieval, among other products and use-cases. It seems to be focused on providing tools for building context-aware, reasoning applications with flexible abstractions and an AI-first toolkit. You can find more information on their website: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mLangchain\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.langchain.com/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Langchain?',\n",
       " 'output': 'Langchain appears to be a platform that offers LangChain, LangSmith, and Retrieval, among other products and use-cases. It seems to be focused on providing tools for building context-aware, reasoning applications with flexible abstractions and an AI-first toolkit. You can find more information on their website: [Langchain](https://www.langchain.com/)'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_embeddings()\n",
    "visualize(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke({\n",
    "    \"input\": \"What's is my name\",\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(content=\"Hi, My name is Tran\"),\n",
    "        AIMessage(content=\"Hello Tran! I dont know your name.\")\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
